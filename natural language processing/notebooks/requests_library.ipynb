{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Requests Library\n",
    "\n",
    "Now that we know how to use BeautifulSoup to get data from HTML files, let's see how we can scrape data from a real website. Unfortunately, Beautifulsoup can't access websites directly. Therefore, in order to access websites, we will use Python's `requests` library. The `requests` library allows us to send web requests and get a website's HTML data. Once the `requests` library gets us the HTML data, we can use Beautifulsoup, just as we did before, to extract the data we want. So let's see an example.\n",
    "\n",
    "In the code below we will use the `requests` library and BeautifulSoup to get `Summary of main facilities operated by Tesla` data from a `html table` the following Wikipedia [webpage](https://en.wikipedia.org/wiki/Tesla,_Inc.). This table corresponds to Tesla's production and sales figures since Q1 2013. We will start by importing the `requests` library by using:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "```\n",
    "\n",
    "We will then use the `requests.get(website)` function to get the source code from our `wikipage`. The `requests.get()` function returns a `Response` object that we will save in the variable `r`. We can get the HTML data we need from this object by using the `.text` method, as shown below. Finally, we'll convert and display the extracted html table into Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a Response object\n",
    "r = requests.get('https://en.wikipedia.org/wiki/Tesla,_Inc.', verify=False)\n",
    "\n",
    "# Get HTML data\n",
    "html_data = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.text` method returns a string, therefore, `html_data` is a string containing the HTML data from our website. Notice, that since `html_data` is a string it can be passed to the BeautifulSoup constructor, and we will do this next, but for now, let's print the `html_data` string to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the HTML data\n",
    "#print(html_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `html_data` indeed contains the HTML data of our website. Notice, that since we are dealing with a real website this time, the HTML file is very long. \n",
    "\n",
    "Now that we have the HTML data from our website, we are ready to use BeautifulSoup just as we did before. The only difference is that this time, instead of passing an open filehandle to the BeautifulSoup constructor, we will pass the `html_data` string. So let's pass `html_data` to the BeautifulSoup constructor to get a BeautifulSoup object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BeautifulSoup Object\n",
    "page_content = BeautifulSoup(html_data, 'html.parser')\n",
    "\n",
    "# Print the BeautifulSoup Object\n",
    "#print(page_content.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a BeautifulSoup object, we can get our sales and production data. To do this, we need to know which tags contain our table data. In order to figure this out, we need to inspect our webpage using our web browser. For this example we will use the Chrome web browser but all web browsers have the same kind of functionality. We begin by going to our wikipage: https://en.wikipedia.org/wiki/Tesla,_Inc.\n",
    "\n",
    "Next, we hover our mouse over around the target html table. As an example, we will hover over the `table header` row. Next, we right-click on the header title for `Quarter` and a dropdown menu will appear. From this menu we will choose **Inspect**. Once we click on **Inspect** we will see the HTML source code of our webpage appear on the right, as shown in the figure below:\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./wikitable.png\" width = \"100%\" style = \"border: thin silver solid; padding: 10px\">\n",
    "</figure> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect the html source code on the right panel, we will see that the table header and rows are all contained within the same `<table>` tag. Therefore, we can use the above information to extract the column title from table header and detail data in the rows. In the code below we use BeautifulSoup's `find()` method to find the target `<table>` tag that has `class=\"wikitable\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complete `html table` can be structured in the following way:\n",
    "```\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Month</th>\n",
    "      <th>Sales</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  \n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>January</td>\n",
    "      <td>$100</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>February</td>\n",
    "      <td>$80</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "  \n",
    "  <tfoot>\n",
    "    <tr>\n",
    "      <td>Sum</td>\n",
    "      <td>$180</td>\n",
    "    </tr>\n",
    "  </tfoot>\n",
    "</table>\n",
    "```\n",
    "\n",
    "But notice that the html table in our wikipage does not have `<thead>` and `<tfoot>` tags. Let's create a BeautifulSoup's object and name it as `wikitable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"wikitable sortable\">\n",
       "<caption>Primary facilities operated by Tesla\n",
       "</caption>\n",
       "<tbody><tr>\n",
       "<th>Opened\n",
       "</th>\n",
       "<th>Name\n",
       "</th>\n",
       "<th>City\n",
       "</th>\n",
       "<th>Country\n",
       "</th>\n",
       "<th>Employees\n",
       "</th>\n",
       "<th>Products\n",
       "</th>\n",
       "<th><abbr title=\"References\">Ref.</abbr>\n",
       "</th></tr>\n",
       "<tr>\n",
       "<td>2010\n",
       "</td>\n",
       "<td><a href=\"/wiki/Tesla_Fremont_Factory\" title=\"Tesla Fremont Factory\">Tesla Fremont Factory</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Fremont,_California\" title=\"Fremont, California\">Fremont, California</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>10,000\n",
       "</td>\n",
       "<td><a href=\"/wiki/Tesla_Model_S\" title=\"Tesla Model S\">Model S</a>, <a href=\"/wiki/Tesla_Model_X\" title=\"Tesla Model X\">Model X</a>, <a href=\"/wiki/Tesla_Model_3\" title=\"Tesla Model 3\">Model 3</a>, <a href=\"/wiki/Tesla_Model_Y\" title=\"Tesla Model Y\">Model Y</a>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-Future_35-1\"><a href=\"#cite_note-Future-35\">[34]</a></sup><sup class=\"reference\" id=\"cite_ref-TC_staff_2020_267-0\"><a href=\"#cite_note-TC_staff_2020-267\">[266]</a></sup><sup class=\"reference\" id=\"cite_ref-268\"><a href=\"#cite_note-268\">[267]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2016\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_Nevada\" title=\"Gigafactory Nevada\">Gigafactory Nevada</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Storey_County,_Nevada\" title=\"Storey County, Nevada\">Storey County, Nevada</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>7,000\n",
       "</td>\n",
       "<td>Batteries, <a href=\"/wiki/Tesla_Powerwall\" title=\"Tesla Powerwall\">Powerwall</a>, <a href=\"/wiki/Tesla_Powerpack\" title=\"Tesla Powerpack\">Powerpack</a>, <a href=\"/wiki/Tesla_Megapack\" title=\"Tesla Megapack\">Megapack</a>, <a href=\"/wiki/Tesla_Semi\" title=\"Tesla Semi\">Semi</a>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-Powerwall_269-0\"><a href=\"#cite_note-Powerwall-269\">[268]</a></sup><sup class=\"reference\" id=\"cite_ref-usatoday_giganevada_2019_270-0\"><a href=\"#cite_note-usatoday_giganevada_2019-270\">[269]</a></sup><sup class=\"reference\" id=\"cite_ref-271\"><a href=\"#cite_note-271\">[270]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2017\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_New_York\" title=\"Gigafactory New York\">Gigafactory New York</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Buffalo,_New_York\" title=\"Buffalo, New York\">Buffalo, New York</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>1,500\n",
       "</td>\n",
       "<td><a class=\"mw-redirect\" href=\"/wiki/Tesla_Solar_Roof\" title=\"Tesla Solar Roof\">Solar Roof</a>, <a href=\"/wiki/Tesla_Supercharger\" title=\"Tesla Supercharger\">Superchargers</a>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-UpAndRunning_272-0\"><a href=\"#cite_note-UpAndRunning-272\">[271]</a></sup><sup class=\"reference\" id=\"cite_ref-CT_giga2_2020_273-0\"><a href=\"#cite_note-CT_giga2_2020-273\">[272]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2019\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_Shanghai\" title=\"Gigafactory Shanghai\">Gigafactory Shanghai</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Shanghai\" title=\"Shanghai\">Shanghai</a>\n",
       "</td>\n",
       "<td>China\n",
       "</td>\n",
       "<td>15,000\n",
       "</td>\n",
       "<td>Model 3, Model Y\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-cnbc20191023_274-0\"><a href=\"#cite_note-cnbc20191023-274\">[273]</a></sup><sup class=\"reference\" id=\"cite_ref-275\"><a href=\"#cite_note-275\">[274]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2022\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_Berlin-Brandenburg\" title=\"Gigafactory Berlin-Brandenburg\">Gigafactory Berlin-Brandenburg</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gr%C3%BCnheide_(Mark)\" title=\"Grünheide (Mark)\">Grünheide</a>\n",
       "</td>\n",
       "<td>Germany\n",
       "</td>\n",
       "<td>10,000\n",
       "</td>\n",
       "<td>Model Y <i>(planned: batteries, Model 3)</i>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-276\"><a href=\"#cite_note-276\">[275]</a></sup><sup class=\"reference\" id=\"cite_ref-277\"><a href=\"#cite_note-277\">[276]</a></sup><sup class=\"reference\" id=\"cite_ref-IEVS_berlin_2021_278-0\"><a href=\"#cite_note-IEVS_berlin_2021-278\">[277]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2022\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_Texas\" title=\"Gigafactory Texas\">Gigafactory Texas</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Austin,_Texas\" title=\"Austin, Texas\">Austin, Texas</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>12,000\n",
       "</td>\n",
       "<td>Model Y, batteries <i>(planned: <a href=\"/wiki/Tesla_Cybertruck\" title=\"Tesla Cybertruck\">Cybertruck</a>, Model 3, Semi)</i>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-279\"><a href=\"#cite_note-279\">[278]</a></sup><sup class=\"reference\" id=\"cite_ref-Vorrath_280-0\"><a href=\"#cite_note-Vorrath-280\">[279]</a></sup><sup class=\"reference\" id=\"cite_ref-281\"><a href=\"#cite_note-281\">[280]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2022\n",
       "</td>\n",
       "<td>Megafactory\n",
       "</td>\n",
       "<td><a href=\"/wiki/Lathrop,_California\" title=\"Lathrop, California\">Lathrop, California</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>1,000\n",
       "</td>\n",
       "<td>Megapack\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-Recordnet-Lathrop_282-0\"><a href=\"#cite_note-Recordnet-Lathrop-282\">[281]</a></sup><sup class=\"reference\" id=\"cite_ref-MR_Bulletin2_283-0\"><a href=\"#cite_note-MR_Bulletin2-283\">[282]</a></sup>\n",
       "</td></tr></tbody></table>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitable = page_content.find('table', {'class': 'wikitable'})\n",
    "wikitable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have extracted the `<table>` tag that have `class=\"wikitable\"` as an object, we can use BeautifulSoup's built-in functions to extract the human-readable text inside this table. Let's grab the information inside `<tbody>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tbody><tr>\n",
       "<th>Opened\n",
       "</th>\n",
       "<th>Name\n",
       "</th>\n",
       "<th>City\n",
       "</th>\n",
       "<th>Country\n",
       "</th>\n",
       "<th>Employees\n",
       "</th>\n",
       "<th>Products\n",
       "</th>\n",
       "<th><abbr title=\"References\">Ref.</abbr>\n",
       "</th></tr>\n",
       "<tr>\n",
       "<td>2010\n",
       "</td>\n",
       "<td><a href=\"/wiki/Tesla_Fremont_Factory\" title=\"Tesla Fremont Factory\">Tesla Fremont Factory</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Fremont,_California\" title=\"Fremont, California\">Fremont, California</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>10,000\n",
       "</td>\n",
       "<td><a href=\"/wiki/Tesla_Model_S\" title=\"Tesla Model S\">Model S</a>, <a href=\"/wiki/Tesla_Model_X\" title=\"Tesla Model X\">Model X</a>, <a href=\"/wiki/Tesla_Model_3\" title=\"Tesla Model 3\">Model 3</a>, <a href=\"/wiki/Tesla_Model_Y\" title=\"Tesla Model Y\">Model Y</a>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-Future_35-1\"><a href=\"#cite_note-Future-35\">[34]</a></sup><sup class=\"reference\" id=\"cite_ref-TC_staff_2020_267-0\"><a href=\"#cite_note-TC_staff_2020-267\">[266]</a></sup><sup class=\"reference\" id=\"cite_ref-268\"><a href=\"#cite_note-268\">[267]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2016\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_Nevada\" title=\"Gigafactory Nevada\">Gigafactory Nevada</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Storey_County,_Nevada\" title=\"Storey County, Nevada\">Storey County, Nevada</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>7,000\n",
       "</td>\n",
       "<td>Batteries, <a href=\"/wiki/Tesla_Powerwall\" title=\"Tesla Powerwall\">Powerwall</a>, <a href=\"/wiki/Tesla_Powerpack\" title=\"Tesla Powerpack\">Powerpack</a>, <a href=\"/wiki/Tesla_Megapack\" title=\"Tesla Megapack\">Megapack</a>, <a href=\"/wiki/Tesla_Semi\" title=\"Tesla Semi\">Semi</a>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-Powerwall_269-0\"><a href=\"#cite_note-Powerwall-269\">[268]</a></sup><sup class=\"reference\" id=\"cite_ref-usatoday_giganevada_2019_270-0\"><a href=\"#cite_note-usatoday_giganevada_2019-270\">[269]</a></sup><sup class=\"reference\" id=\"cite_ref-271\"><a href=\"#cite_note-271\">[270]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2017\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_New_York\" title=\"Gigafactory New York\">Gigafactory New York</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Buffalo,_New_York\" title=\"Buffalo, New York\">Buffalo, New York</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>1,500\n",
       "</td>\n",
       "<td><a class=\"mw-redirect\" href=\"/wiki/Tesla_Solar_Roof\" title=\"Tesla Solar Roof\">Solar Roof</a>, <a href=\"/wiki/Tesla_Supercharger\" title=\"Tesla Supercharger\">Superchargers</a>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-UpAndRunning_272-0\"><a href=\"#cite_note-UpAndRunning-272\">[271]</a></sup><sup class=\"reference\" id=\"cite_ref-CT_giga2_2020_273-0\"><a href=\"#cite_note-CT_giga2_2020-273\">[272]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2019\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_Shanghai\" title=\"Gigafactory Shanghai\">Gigafactory Shanghai</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Shanghai\" title=\"Shanghai\">Shanghai</a>\n",
       "</td>\n",
       "<td>China\n",
       "</td>\n",
       "<td>15,000\n",
       "</td>\n",
       "<td>Model 3, Model Y\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-cnbc20191023_274-0\"><a href=\"#cite_note-cnbc20191023-274\">[273]</a></sup><sup class=\"reference\" id=\"cite_ref-275\"><a href=\"#cite_note-275\">[274]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2022\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_Berlin-Brandenburg\" title=\"Gigafactory Berlin-Brandenburg\">Gigafactory Berlin-Brandenburg</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gr%C3%BCnheide_(Mark)\" title=\"Grünheide (Mark)\">Grünheide</a>\n",
       "</td>\n",
       "<td>Germany\n",
       "</td>\n",
       "<td>10,000\n",
       "</td>\n",
       "<td>Model Y <i>(planned: batteries, Model 3)</i>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-276\"><a href=\"#cite_note-276\">[275]</a></sup><sup class=\"reference\" id=\"cite_ref-277\"><a href=\"#cite_note-277\">[276]</a></sup><sup class=\"reference\" id=\"cite_ref-IEVS_berlin_2021_278-0\"><a href=\"#cite_note-IEVS_berlin_2021-278\">[277]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2022\n",
       "</td>\n",
       "<td><a href=\"/wiki/Gigafactory_Texas\" title=\"Gigafactory Texas\">Gigafactory Texas</a>\n",
       "</td>\n",
       "<td><a href=\"/wiki/Austin,_Texas\" title=\"Austin, Texas\">Austin, Texas</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>12,000\n",
       "</td>\n",
       "<td>Model Y, batteries <i>(planned: <a href=\"/wiki/Tesla_Cybertruck\" title=\"Tesla Cybertruck\">Cybertruck</a>, Model 3, Semi)</i>\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-279\"><a href=\"#cite_note-279\">[278]</a></sup><sup class=\"reference\" id=\"cite_ref-Vorrath_280-0\"><a href=\"#cite_note-Vorrath-280\">[279]</a></sup><sup class=\"reference\" id=\"cite_ref-281\"><a href=\"#cite_note-281\">[280]</a></sup>\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2022\n",
       "</td>\n",
       "<td>Megafactory\n",
       "</td>\n",
       "<td><a href=\"/wiki/Lathrop,_California\" title=\"Lathrop, California\">Lathrop, California</a>\n",
       "</td>\n",
       "<td>United States\n",
       "</td>\n",
       "<td>1,000\n",
       "</td>\n",
       "<td>Megapack\n",
       "</td>\n",
       "<td><sup class=\"reference\" id=\"cite_ref-Recordnet-Lathrop_282-0\"><a href=\"#cite_note-Recordnet-Lathrop-282\">[281]</a></sup><sup class=\"reference\" id=\"cite_ref-MR_Bulletin2_283-0\"><a href=\"#cite_note-MR_Bulletin2-283\">[282]</a></sup>\n",
       "</td></tr></tbody>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitable.tbody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the earlier cell, we use `find()` function to get the html table. Now, we are going to use `findAll()` function to grab all the defined tags inside the BeautifulSoup object. In this case, we want to extract every row in the `<tbody>` tag and we can do so by using `findAll()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr>\n",
       " <th>Opened\n",
       " </th>\n",
       " <th>Name\n",
       " </th>\n",
       " <th>City\n",
       " </th>\n",
       " <th>Country\n",
       " </th>\n",
       " <th>Employees\n",
       " </th>\n",
       " <th>Products\n",
       " </th>\n",
       " <th><abbr title=\"References\">Ref.</abbr>\n",
       " </th></tr>, <tr>\n",
       " <td>2010\n",
       " </td>\n",
       " <td><a href=\"/wiki/Tesla_Fremont_Factory\" title=\"Tesla Fremont Factory\">Tesla Fremont Factory</a>\n",
       " </td>\n",
       " <td><a href=\"/wiki/Fremont,_California\" title=\"Fremont, California\">Fremont, California</a>\n",
       " </td>\n",
       " <td>United States\n",
       " </td>\n",
       " <td>10,000\n",
       " </td>\n",
       " <td><a href=\"/wiki/Tesla_Model_S\" title=\"Tesla Model S\">Model S</a>, <a href=\"/wiki/Tesla_Model_X\" title=\"Tesla Model X\">Model X</a>, <a href=\"/wiki/Tesla_Model_3\" title=\"Tesla Model 3\">Model 3</a>, <a href=\"/wiki/Tesla_Model_Y\" title=\"Tesla Model Y\">Model Y</a>\n",
       " </td>\n",
       " <td><sup class=\"reference\" id=\"cite_ref-Future_35-1\"><a href=\"#cite_note-Future-35\">[34]</a></sup><sup class=\"reference\" id=\"cite_ref-TC_staff_2020_267-0\"><a href=\"#cite_note-TC_staff_2020-267\">[266]</a></sup><sup class=\"reference\" id=\"cite_ref-268\"><a href=\"#cite_note-268\">[267]</a></sup>\n",
       " </td></tr>, <tr>\n",
       " <td>2016\n",
       " </td>\n",
       " <td><a href=\"/wiki/Gigafactory_Nevada\" title=\"Gigafactory Nevada\">Gigafactory Nevada</a>\n",
       " </td>\n",
       " <td><a href=\"/wiki/Storey_County,_Nevada\" title=\"Storey County, Nevada\">Storey County, Nevada</a>\n",
       " </td>\n",
       " <td>United States\n",
       " </td>\n",
       " <td>7,000\n",
       " </td>\n",
       " <td>Batteries, <a href=\"/wiki/Tesla_Powerwall\" title=\"Tesla Powerwall\">Powerwall</a>, <a href=\"/wiki/Tesla_Powerpack\" title=\"Tesla Powerpack\">Powerpack</a>, <a href=\"/wiki/Tesla_Megapack\" title=\"Tesla Megapack\">Megapack</a>, <a href=\"/wiki/Tesla_Semi\" title=\"Tesla Semi\">Semi</a>\n",
       " </td>\n",
       " <td><sup class=\"reference\" id=\"cite_ref-Powerwall_269-0\"><a href=\"#cite_note-Powerwall-269\">[268]</a></sup><sup class=\"reference\" id=\"cite_ref-usatoday_giganevada_2019_270-0\"><a href=\"#cite_note-usatoday_giganevada_2019-270\">[269]</a></sup><sup class=\"reference\" id=\"cite_ref-271\"><a href=\"#cite_note-271\">[270]</a></sup>\n",
       " </td></tr>, <tr>\n",
       " <td>2017\n",
       " </td>\n",
       " <td><a href=\"/wiki/Gigafactory_New_York\" title=\"Gigafactory New York\">Gigafactory New York</a>\n",
       " </td>\n",
       " <td><a href=\"/wiki/Buffalo,_New_York\" title=\"Buffalo, New York\">Buffalo, New York</a>\n",
       " </td>\n",
       " <td>United States\n",
       " </td>\n",
       " <td>1,500\n",
       " </td>\n",
       " <td><a class=\"mw-redirect\" href=\"/wiki/Tesla_Solar_Roof\" title=\"Tesla Solar Roof\">Solar Roof</a>, <a href=\"/wiki/Tesla_Supercharger\" title=\"Tesla Supercharger\">Superchargers</a>\n",
       " </td>\n",
       " <td><sup class=\"reference\" id=\"cite_ref-UpAndRunning_272-0\"><a href=\"#cite_note-UpAndRunning-272\">[271]</a></sup><sup class=\"reference\" id=\"cite_ref-CT_giga2_2020_273-0\"><a href=\"#cite_note-CT_giga2_2020-273\">[272]</a></sup>\n",
       " </td></tr>, <tr>\n",
       " <td>2019\n",
       " </td>\n",
       " <td><a href=\"/wiki/Gigafactory_Shanghai\" title=\"Gigafactory Shanghai\">Gigafactory Shanghai</a>\n",
       " </td>\n",
       " <td><a href=\"/wiki/Shanghai\" title=\"Shanghai\">Shanghai</a>\n",
       " </td>\n",
       " <td>China\n",
       " </td>\n",
       " <td>15,000\n",
       " </td>\n",
       " <td>Model 3, Model Y\n",
       " </td>\n",
       " <td><sup class=\"reference\" id=\"cite_ref-cnbc20191023_274-0\"><a href=\"#cite_note-cnbc20191023-274\">[273]</a></sup><sup class=\"reference\" id=\"cite_ref-275\"><a href=\"#cite_note-275\">[274]</a></sup>\n",
       " </td></tr>, <tr>\n",
       " <td>2022\n",
       " </td>\n",
       " <td><a href=\"/wiki/Gigafactory_Berlin-Brandenburg\" title=\"Gigafactory Berlin-Brandenburg\">Gigafactory Berlin-Brandenburg</a>\n",
       " </td>\n",
       " <td><a href=\"/wiki/Gr%C3%BCnheide_(Mark)\" title=\"Grünheide (Mark)\">Grünheide</a>\n",
       " </td>\n",
       " <td>Germany\n",
       " </td>\n",
       " <td>10,000\n",
       " </td>\n",
       " <td>Model Y <i>(planned: batteries, Model 3)</i>\n",
       " </td>\n",
       " <td><sup class=\"reference\" id=\"cite_ref-276\"><a href=\"#cite_note-276\">[275]</a></sup><sup class=\"reference\" id=\"cite_ref-277\"><a href=\"#cite_note-277\">[276]</a></sup><sup class=\"reference\" id=\"cite_ref-IEVS_berlin_2021_278-0\"><a href=\"#cite_note-IEVS_berlin_2021-278\">[277]</a></sup>\n",
       " </td></tr>, <tr>\n",
       " <td>2022\n",
       " </td>\n",
       " <td><a href=\"/wiki/Gigafactory_Texas\" title=\"Gigafactory Texas\">Gigafactory Texas</a>\n",
       " </td>\n",
       " <td><a href=\"/wiki/Austin,_Texas\" title=\"Austin, Texas\">Austin, Texas</a>\n",
       " </td>\n",
       " <td>United States\n",
       " </td>\n",
       " <td>12,000\n",
       " </td>\n",
       " <td>Model Y, batteries <i>(planned: <a href=\"/wiki/Tesla_Cybertruck\" title=\"Tesla Cybertruck\">Cybertruck</a>, Model 3, Semi)</i>\n",
       " </td>\n",
       " <td><sup class=\"reference\" id=\"cite_ref-279\"><a href=\"#cite_note-279\">[278]</a></sup><sup class=\"reference\" id=\"cite_ref-Vorrath_280-0\"><a href=\"#cite_note-Vorrath-280\">[279]</a></sup><sup class=\"reference\" id=\"cite_ref-281\"><a href=\"#cite_note-281\">[280]</a></sup>\n",
       " </td></tr>, <tr>\n",
       " <td>2022\n",
       " </td>\n",
       " <td>Megafactory\n",
       " </td>\n",
       " <td><a href=\"/wiki/Lathrop,_California\" title=\"Lathrop, California\">Lathrop, California</a>\n",
       " </td>\n",
       " <td>United States\n",
       " </td>\n",
       " <td>1,000\n",
       " </td>\n",
       " <td>Megapack\n",
       " </td>\n",
       " <td><sup class=\"reference\" id=\"cite_ref-Recordnet-Lathrop_282-0\"><a href=\"#cite_note-Recordnet-Lathrop-282\">[281]</a></sup><sup class=\"reference\" id=\"cite_ref-MR_Bulletin2_283-0\"><a href=\"#cite_note-MR_Bulletin2-283\">[282]</a></sup>\n",
       " </td></tr>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitable.tbody.findAll('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the html source code above, the first row consists of the column name and followed by the actual data in the subsequent rows. Let's grab the `column names` from the first row and all the `<th>` tags inside the row.\n",
    "\n",
    "Notice the row index of `[0]` after `findAll('tr')` to get the first row. Then, we can chain the second `findAll()` function to get all the `<th>` tags inside this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<th>Opened\n",
       " </th>, <th>Name\n",
       " </th>, <th>City\n",
       " </th>, <th>Country\n",
       " </th>, <th>Employees\n",
       " </th>, <th>Products\n",
       " </th>, <th><abbr title=\"References\">Ref.</abbr>\n",
       " </th>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikicolumns = wikitable.tbody.findAll('tr')[0].findAll('th')\n",
    "wikicolumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the column names in a Python object, called `df_columns`, so we can use it to build Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Opened' 'Name' 'City' 'Country' 'Employees' 'Products' 'Ref.']\n"
     ]
    }
   ],
   "source": [
    "df_columns = []\n",
    "\n",
    "for column in wikicolumns:\n",
    "    # remove <br/> inside <th> text, such as `<th>Total<br/>production</th>`\n",
    "    text = column.get_text(strip=True, separator=\" \")\n",
    "    # append the text into df_columns\n",
    "    df_columns.append(text)\n",
    "print(np.array(df_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we hava stored the column names, now we want to iterate the remaining rows, consisting the real data in this table. We can use Python `for loop` function to iterate from the second row onward. To do so, we need to set the starting index as follows: `wikitable.tbody.findAll('tr')[1:]`. Let's store our dataset in Python object, called `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['2010', 'Tesla Fremont Factory', 'Fremont, California',\n",
      "       'United States', '10,000', 'Model S , Model X , Model 3 , Model Y',\n",
      "       '[34] [266] [267]'], \n",
      "      dtype='<U37'), array(['2016', 'Gigafactory Nevada', 'Storey County, Nevada',\n",
      "       'United States', '7,000',\n",
      "       'Batteries, Powerwall , Powerpack , Megapack , Semi',\n",
      "       '[268] [269] [270]'], \n",
      "      dtype='<U50'), array(['2017', 'Gigafactory New York', 'Buffalo, New York',\n",
      "       'United States', '1,500', 'Solar Roof , Superchargers',\n",
      "       '[271] [272]'], \n",
      "      dtype='<U26'), array(['2019', 'Gigafactory Shanghai', 'Shanghai', 'China', '15,000',\n",
      "       'Model 3, Model Y', '[273] [274]'], \n",
      "      dtype='<U20'), array(['2022', 'Gigafactory Berlin-Brandenburg', 'Grünheide', 'Germany',\n",
      "       '10,000', 'Model Y (planned: batteries, Model 3)',\n",
      "       '[275] [276] [277]'], \n",
      "      dtype='<U37'), array(['2022', 'Gigafactory Texas', 'Austin, Texas', 'United States',\n",
      "       '12,000',\n",
      "       'Model Y, batteries (planned: Cybertruck , Model 3, Semi)',\n",
      "       '[278] [279] [280]'], \n",
      "      dtype='<U56'), array(['2022', 'Megafactory', 'Lathrop, California', 'United States',\n",
      "       '1,000', 'Megapack', '[281] [282]'], \n",
      "      dtype='<U19')]\n"
     ]
    }
   ],
   "source": [
    "df_data = []\n",
    "\n",
    "for row in wikitable.tbody.findAll('tr')[1:]:\n",
    "    row_data = []\n",
    "    for td in row.findAll('td'):\n",
    "        text = td.get_text(strip=True, separator=\" \")\n",
    "        row_data.append(text)\n",
    "    df_data.append(np.array(row_data))\n",
    "\n",
    "# print the first 10 data rows\n",
    "print(df_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have grabbed the column names and data. But we want to present the data in human-readable structure. We can use [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) library. Pandas DataFrame is similar to Excel spreadsheet and Google Sheet. This library provides a convenient data structure to manipulate and present data with Python.\n",
    "\n",
    "Let's create a Panda DataFrame object, called `dataframe`, so we can present our data in a spreadsheet structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opened</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Products</th>\n",
       "      <th>Ref.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Tesla Fremont Factory</td>\n",
       "      <td>Fremont, California</td>\n",
       "      <td>United States</td>\n",
       "      <td>10,000</td>\n",
       "      <td>Model S , Model X , Model 3 , Model Y</td>\n",
       "      <td>[34] [266] [267]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Gigafactory Nevada</td>\n",
       "      <td>Storey County, Nevada</td>\n",
       "      <td>United States</td>\n",
       "      <td>7,000</td>\n",
       "      <td>Batteries, Powerwall , Powerpack , Megapack , ...</td>\n",
       "      <td>[268] [269] [270]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Gigafactory New York</td>\n",
       "      <td>Buffalo, New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>1,500</td>\n",
       "      <td>Solar Roof , Superchargers</td>\n",
       "      <td>[271] [272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Gigafactory Shanghai</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>China</td>\n",
       "      <td>15,000</td>\n",
       "      <td>Model 3, Model Y</td>\n",
       "      <td>[273] [274]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>Gigafactory Berlin-Brandenburg</td>\n",
       "      <td>Grünheide</td>\n",
       "      <td>Germany</td>\n",
       "      <td>10,000</td>\n",
       "      <td>Model Y (planned: batteries, Model 3)</td>\n",
       "      <td>[275] [276] [277]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022</td>\n",
       "      <td>Gigafactory Texas</td>\n",
       "      <td>Austin, Texas</td>\n",
       "      <td>United States</td>\n",
       "      <td>12,000</td>\n",
       "      <td>Model Y, batteries (planned: Cybertruck , Mode...</td>\n",
       "      <td>[278] [279] [280]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>Megafactory</td>\n",
       "      <td>Lathrop, California</td>\n",
       "      <td>United States</td>\n",
       "      <td>1,000</td>\n",
       "      <td>Megapack</td>\n",
       "      <td>[281] [282]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Opened                            Name                   City  \\\n",
       "0   2010           Tesla Fremont Factory    Fremont, California   \n",
       "1   2016              Gigafactory Nevada  Storey County, Nevada   \n",
       "2   2017            Gigafactory New York      Buffalo, New York   \n",
       "3   2019            Gigafactory Shanghai               Shanghai   \n",
       "4   2022  Gigafactory Berlin-Brandenburg              Grünheide   \n",
       "5   2022               Gigafactory Texas          Austin, Texas   \n",
       "6   2022                     Megafactory    Lathrop, California   \n",
       "\n",
       "         Country Employees                                           Products  \\\n",
       "0  United States    10,000              Model S , Model X , Model 3 , Model Y   \n",
       "1  United States     7,000  Batteries, Powerwall , Powerpack , Megapack , ...   \n",
       "2  United States     1,500                         Solar Roof , Superchargers   \n",
       "3          China    15,000                                   Model 3, Model Y   \n",
       "4        Germany    10,000              Model Y (planned: batteries, Model 3)   \n",
       "5  United States    12,000  Model Y, batteries (planned: Cybertruck , Mode...   \n",
       "6  United States     1,000                                           Megapack   \n",
       "\n",
       "                Ref.  \n",
       "0   [34] [266] [267]  \n",
       "1  [268] [269] [270]  \n",
       "2        [271] [272]  \n",
       "3        [273] [274]  \n",
       "4  [275] [276] [277]  \n",
       "5  [278] [279] [280]  \n",
       "6        [281] [282]  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data=df_data, columns=df_columns)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job! We have extracted Tesla's production and sales data from an `html table` in a Wikipage and converted the data into Python and Pandas DataFrame. It's now your time to practice with `requests` and `BeautifulSoup` libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Get Amazon financial data from Wikipage\n",
    "\n",
    "URL links:\n",
    "- Wikipage: https://en.wikipedia.org/wiki/Amazon_(company) <br/>\n",
    "- Financial data: https://en.wikipedia.org/wiki/Amazon_(company)#Finances\n",
    "\n",
    "Tasks: <br/>\n",
    "Start by importing the `BeautifulSoup` and `requests` libraries. Then use the `requests.get()` function with the appropriate `params` to get our website's HTML data. Then create a BeautifulSoup Object named `page_content` using our website's HTML data and the `html.parser` parser. Then use the `find()` method to find the `<table>` tag. Then, get the table column names. Finally, create a loop that prints all the countries and population from `<tbody>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revenue [154] in mil. US$</th>\n",
       "      <th>Net income in mil. US$</th>\n",
       "      <th>Total Assets in mil. US$</th>\n",
       "      <th>Employees</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995 [155]</th>\n",
       "      <td>0.5</td>\n",
       "      <td>−0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996 [155]</th>\n",
       "      <td>16</td>\n",
       "      <td>−6</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997 [155]</th>\n",
       "      <td>148</td>\n",
       "      <td>−28</td>\n",
       "      <td>149</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998 [156]</th>\n",
       "      <td>610</td>\n",
       "      <td>−124</td>\n",
       "      <td>648</td>\n",
       "      <td>2,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999 [156]</th>\n",
       "      <td>1,639</td>\n",
       "      <td>−720</td>\n",
       "      <td>2,466</td>\n",
       "      <td>7,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000 [156]</th>\n",
       "      <td>2,761</td>\n",
       "      <td>−1,411</td>\n",
       "      <td>2,135</td>\n",
       "      <td>9,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001 [156]</th>\n",
       "      <td>3,122</td>\n",
       "      <td>−567</td>\n",
       "      <td>1,638</td>\n",
       "      <td>7,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002 [156]</th>\n",
       "      <td>3,932</td>\n",
       "      <td>−149</td>\n",
       "      <td>1,990</td>\n",
       "      <td>7,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003 [157]</th>\n",
       "      <td>5,263</td>\n",
       "      <td>35</td>\n",
       "      <td>2,162</td>\n",
       "      <td>7,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004 [157]</th>\n",
       "      <td>6,921</td>\n",
       "      <td>588</td>\n",
       "      <td>3,248</td>\n",
       "      <td>9,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005 [157]</th>\n",
       "      <td>8,490</td>\n",
       "      <td>359</td>\n",
       "      <td>3,696</td>\n",
       "      <td>12,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006 [157]</th>\n",
       "      <td>10,711</td>\n",
       "      <td>190</td>\n",
       "      <td>4,363</td>\n",
       "      <td>13,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007 [157]</th>\n",
       "      <td>14,835</td>\n",
       "      <td>476</td>\n",
       "      <td>6,485</td>\n",
       "      <td>17,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008 [158]</th>\n",
       "      <td>19,166</td>\n",
       "      <td>645</td>\n",
       "      <td>8,314</td>\n",
       "      <td>20,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009 [159]</th>\n",
       "      <td>24,509</td>\n",
       "      <td>902</td>\n",
       "      <td>13,813</td>\n",
       "      <td>24,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010 [160]</th>\n",
       "      <td>34,204</td>\n",
       "      <td>1,152</td>\n",
       "      <td>18,797</td>\n",
       "      <td>33,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011 [161]</th>\n",
       "      <td>48,077</td>\n",
       "      <td>631</td>\n",
       "      <td>25,278</td>\n",
       "      <td>56,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012 [162]</th>\n",
       "      <td>61,093</td>\n",
       "      <td>−39</td>\n",
       "      <td>32,555</td>\n",
       "      <td>88,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013 [163]</th>\n",
       "      <td>74,452</td>\n",
       "      <td>274</td>\n",
       "      <td>40,159</td>\n",
       "      <td>117,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014 [164]</th>\n",
       "      <td>88,988</td>\n",
       "      <td>−241</td>\n",
       "      <td>54,505</td>\n",
       "      <td>154,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015 [165]</th>\n",
       "      <td>107,006</td>\n",
       "      <td>596</td>\n",
       "      <td>64,747</td>\n",
       "      <td>230,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016 [166]</th>\n",
       "      <td>135,987</td>\n",
       "      <td>2,371</td>\n",
       "      <td>83,402</td>\n",
       "      <td>341,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017 [167]</th>\n",
       "      <td>177,866</td>\n",
       "      <td>3,033</td>\n",
       "      <td>131,310</td>\n",
       "      <td>566,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018 [168]</th>\n",
       "      <td>232,887</td>\n",
       "      <td>10,073</td>\n",
       "      <td>162,648</td>\n",
       "      <td>647,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019 [169]</th>\n",
       "      <td>280,522</td>\n",
       "      <td>11,588</td>\n",
       "      <td>225,248</td>\n",
       "      <td>798,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020 [170]</th>\n",
       "      <td>386,064</td>\n",
       "      <td>21,331</td>\n",
       "      <td>321,195</td>\n",
       "      <td>1,298,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021 [1]</th>\n",
       "      <td>469,822</td>\n",
       "      <td>33,364</td>\n",
       "      <td>420,549</td>\n",
       "      <td>1,608,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022 [1]</th>\n",
       "      <td>513,983</td>\n",
       "      <td>−2,722</td>\n",
       "      <td>462,675</td>\n",
       "      <td>1,541,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Revenue [154] in mil. US$ Net income in mil. US$  \\\n",
       "Year                                                          \n",
       "1995 [155]                       0.5                   −0.3   \n",
       "1996 [155]                        16                     −6   \n",
       "1997 [155]                       148                    −28   \n",
       "1998 [156]                       610                   −124   \n",
       "1999 [156]                     1,639                   −720   \n",
       "2000 [156]                     2,761                 −1,411   \n",
       "2001 [156]                     3,122                   −567   \n",
       "2002 [156]                     3,932                   −149   \n",
       "2003 [157]                     5,263                     35   \n",
       "2004 [157]                     6,921                    588   \n",
       "2005 [157]                     8,490                    359   \n",
       "2006 [157]                    10,711                    190   \n",
       "2007 [157]                    14,835                    476   \n",
       "2008 [158]                    19,166                    645   \n",
       "2009 [159]                    24,509                    902   \n",
       "2010 [160]                    34,204                  1,152   \n",
       "2011 [161]                    48,077                    631   \n",
       "2012 [162]                    61,093                    −39   \n",
       "2013 [163]                    74,452                    274   \n",
       "2014 [164]                    88,988                   −241   \n",
       "2015 [165]                   107,006                    596   \n",
       "2016 [166]                   135,987                  2,371   \n",
       "2017 [167]                   177,866                  3,033   \n",
       "2018 [168]                   232,887                 10,073   \n",
       "2019 [169]                   280,522                 11,588   \n",
       "2020 [170]                   386,064                 21,331   \n",
       "2021 [1]                     469,822                 33,364   \n",
       "2022 [1]                     513,983                 −2,722   \n",
       "\n",
       "           Total Assets in mil. US$  Employees  \n",
       "Year                                            \n",
       "1995 [155]                      1.1             \n",
       "1996 [155]                        8             \n",
       "1997 [155]                      149        614  \n",
       "1998 [156]                      648      2,100  \n",
       "1999 [156]                    2,466      7,600  \n",
       "2000 [156]                    2,135      9,000  \n",
       "2001 [156]                    1,638      7,800  \n",
       "2002 [156]                    1,990      7,500  \n",
       "2003 [157]                    2,162      7,800  \n",
       "2004 [157]                    3,248      9,000  \n",
       "2005 [157]                    3,696     12,000  \n",
       "2006 [157]                    4,363     13,900  \n",
       "2007 [157]                    6,485     17,000  \n",
       "2008 [158]                    8,314     20,700  \n",
       "2009 [159]                   13,813     24,300  \n",
       "2010 [160]                   18,797     33,700  \n",
       "2011 [161]                   25,278     56,200  \n",
       "2012 [162]                   32,555     88,400  \n",
       "2013 [163]                   40,159    117,300  \n",
       "2014 [164]                   54,505    154,100  \n",
       "2015 [165]                   64,747    230,800  \n",
       "2016 [166]                   83,402    341,400  \n",
       "2017 [167]                  131,310    566,000  \n",
       "2018 [168]                  162,648    647,500  \n",
       "2019 [169]                  225,248    798,000  \n",
       "2020 [170]                  321,195  1,298,000  \n",
       "2021 [1]                    420,549  1,608,000  \n",
       "2022 [1]                    462,675  1,541,000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a Response object\n",
    "r = requests.get('https://en.wikipedia.org/wiki/Amazon_(company)')\n",
    "\n",
    "# Get HTML data\n",
    "html_data = r.text\n",
    "\n",
    "# Create a BeautifulSoup Object\n",
    "page_content = BeautifulSoup(html_data, 'html.parser')\n",
    "\n",
    "# Find financial table\n",
    "# since there are two wikitable on the website, we use find_all() method which rerurns a list\n",
    "# and take the second table\n",
    "# instead of find() method just return the first element\n",
    "wikitables = page_content.find_all('table', class_='wikitable')\n",
    "wikitable = wikitables[1]\n",
    "#print(wikitable)\n",
    "\n",
    "# Find all column titles\n",
    "# find all tr tags, get the first tr tags, and then get all the th tags\n",
    "\n",
    "th_list = wikitable.find_all('tr')[0].find_all('th')\n",
    "#print(th_list)\n",
    "\n",
    "# loop over th_list and strip all 'th' tag and get the column name of the dataframe\n",
    "wikicolumns = []\n",
    "for tag in th_list:\n",
    "    text = tag.get_text(strip = True, separator=\" \")\n",
    "    wikicolumns.append(text)\n",
    "#print(wikicolumns)\n",
    "\n",
    "#wikicolumns = [i.get_text(strip=True, separator=\" \") for i in wikitable.find_all('tr')[0].find_all('td')]\n",
    "#wikicolumns\n",
    "# Loop through column titles and store into Python array\n",
    "#df_columns = np.array(wikicolumns)\n",
    "#print(df_columns)\n",
    "\n",
    "# Loop through the data rows and store into Python array\n",
    "# loop from the first tr tags\n",
    "# for each tr tag find all td tags\n",
    "# loop over and strip all td tags\n",
    "df_data = []\n",
    "for tr in wikitable.find_all('tr')[1:]:\n",
    "    td_list=[]\n",
    "    for tag in tr.find_all('td'):\n",
    "        td_text = tag.get_text(strip = True, separator=\" \")\n",
    "        td_list.append(td_text)\n",
    "    #th_array = np.array(td_list)\n",
    "    df_data.append(td_list)\n",
    "#print(df_data)\n",
    "        \n",
    "\n",
    "\n",
    "# Print financial data in DataFrame format and set `Year` as index\n",
    "dataframe = pd.DataFrame(df_data, columns = wikicolumns)\n",
    "dataframe.set_index('Year', inplace = True)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML\n",
    "\n",
    "Throughout these lessons we have used HTML files and BeautifulSoup's `html_parser` to show you how to scrape data. We should note that the exact same techniques can be applied to XML files. The only difference is that you will have to use an XML parser in the BeautifulSoup constructor. For example, in order to parse a document as XML, you can use `lxml`’s XML parser by passing in `xml` as the second argument to the BeautifulSoup constructor:\n",
    "\n",
    "```python\n",
    "page_content = BeautifulSoup(xml_file, 'xml')\n",
    "```\n",
    "\n",
    "The above statement will parse the given `xml_file` as XML using the `xml` parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Remarks\n",
    "\n",
    "So now you should know how to scrape data from websites using the `requests` and `BeautifulSoup` libraries. We should note, that you should be careful when scrapping websites not to overwhelm a website's server. This can happen if you write computer programs that send out a lot of requests very quickly. Doing this, will overwhelm the server and probably cause it to get stuck. This is obviously very bad, so avoid making tons of web requests in a short amount of time. In fact, some servers monitor if you are making too many requests and block you, if you are doing so. So keep this in mind when you are writing computer programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "[Solution notebook](requests_library_solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "147px",
    "width": "322px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
